{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Practical"
      ],
      "metadata": {
        "id": "edupcwPE6zix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Write a Python script to visualize the distribution of errors (residuals) for a multiple linear regression model\n",
        "using Seaborn's \"diamonds\" dataset."
      ],
      "metadata": {
        "id": "tLk7UqirBIUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the diamonds dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Prepare the data\n",
        "# Select features and target variable\n",
        "X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]  # Features\n",
        "y = diamonds['price']  # Target\n",
        "\n",
        "# Handle missing values (if any) - Impute with mean for demonstration\n",
        "for col in X.columns:\n",
        "    X[col].fillna(X[col].mean(), inplace=True)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate residuals (errors)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Visualize the distribution of residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Optional: Q-Q plot for normality check\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot of Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M53BSAUCxx8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a Python script to calculate and print Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root\n",
        "Mean Squared Error (RMSE) for a linear regression model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5HxLNboHBy6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Calculate MSE, MAE, and RMSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        ""
      ],
      "metadata": {
        "id": "_f6MTwLJyGtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Given values\n",
        "Y_true = [1,1,2,2,4]  # Y_true = Y (original values)\n",
        "\n",
        "# calculated values\n",
        "Y_pred = [0.6,1.29,1.99,2.69,3.4]  # Y_pred = Y'\n",
        "\n",
        "# Calculation of Mean Squared Error (MSE)\n",
        "mean_squared_error(Y_true,Y_pred)"
      ],
      "metadata": {
        "id": "jsN3GB6m8osD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3.Write a Python script to check if the assumptions of linear regression are met. Use a scatter plot to check\n",
        "linearity, residuals plot for homoscedasticity, and correlation matrix for multicollinearity."
      ],
      "metadata": {
        "id": "PzZIfXt4AZsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Load the diamonds dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Prepare the data\n",
        "# Select features and target variable\n",
        "X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]  # Features\n",
        "y = diamonds['price']  # Target\n",
        "\n",
        "# Handle missing values (if any) - Impute with mean for demonstration\n",
        "for col in X.columns:\n",
        "    X[col].fillna(X[col].mean(), inplace=True)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate residuals (errors)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# 1. Linearity: Scatter plot of predicted vs actual values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_pred, y_test)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Actual Values\")\n",
        "plt.title(\"Linearity Check: Predicted vs Actual\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Homoscedasticity: Residuals plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_pred, residuals)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Homoscedasticity Check: Residuals vs Predicted\")\n",
        "plt.axhline(y=0, color='r', linestyle='--')  # Add a horizontal line at y=0\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 3. Multicollinearity: Correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = X.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Multicollinearity Check: Correlation Matrix of Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aXkDJOhXyWF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python script that creates a machine learning pipeline with feature scaling and evaluates the\n",
        "performance of different regression models"
      ],
      "metadata": {
        "id": "30fOZdynEBGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the diamonds dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Prepare the data (same as before)\n",
        "X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]\n",
        "y = diamonds['price']\n",
        "\n",
        "for col in X.columns:\n",
        "    X[col].fillna(X[col].mean(), inplace=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(),\n",
        "    \"Lasso Regression\": Lasso(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(),\n",
        "    \"Support Vector Regression\": SVR()\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results.append([name, mse, r2])\n",
        "\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Mean Squared Error\", \"R-squared\"])\n",
        "results_df\n",
        ""
      ],
      "metadata": {
        "id": "g5QlXmBsyeo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5.Implement a simple linear regression model on a dataset and print the model's coefficients, intercept, and\n",
        "R-squared score"
      ],
      "metadata": {
        "id": "um4pZhtVEz8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already loaded the data and split it into X_train, X_test, y_train, y_test as in the provided code.\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print the coefficients and intercept\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "\n",
        "# Calculate and print the R-squared score\n",
        "r_squared = model.score(X_test, y_test)\n",
        "print(\"R-squared:\", r_squared)\n",
        ""
      ],
      "metadata": {
        "id": "vKFi9R6IyusT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Write a Python script that analyzes the relationship between total bill and tip in the 'tips' dataset using\n",
        "simple linear regression and visualizes the results."
      ],
      "metadata": {
        "id": "ogQOm4kyE8GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Prepare the data\n",
        "X = tips[['total_bill']]  # Feature: total_bill\n",
        "y = tips['tip']  # Target: tip\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
        "plt.plot(X_test, y_pred, color='red', label='Predicted')\n",
        "plt.xlabel('Total Bill')\n",
        "plt.ylabel('Tip')\n",
        "plt.title('Simple Linear Regression: Total Bill vs. Tip')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print model coefficients and intercept\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "metadata": {
        "id": "ciR-9WjTzV9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Write a Python script that fits a linear regression model to a synthetic dataset with one feature. Use the\n",
        "model to predict new values and plot the data points along with the regression line."
      ],
      "metadata": {
        "id": "yJtAdsGDE8Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2 * X + 1 + np.random.randn(100, 1)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict new values\n",
        "X_new = np.array([[0], [10]])\n",
        "y_pred = model.predict(X_new)\n",
        "\n",
        "# Plot the data points and the regression line\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.plot(X_new, y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression on Synthetic Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vI1-IOaGzhCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Write a Python script that pickles a trained linear regression model and saves it to a file."
      ],
      "metadata": {
        "id": "ruiOps6gE8eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming 'model' is your trained linear regression model (as in the previous examples)\n",
        "# ... (your code to train the model) ...\n",
        "\n",
        "# Save the model to a file using pickle\n",
        "filename = 'linear_regression_model.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(f\"Model saved to {filename}\")"
      ],
      "metadata": {
        "id": "WASjNlokzojU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 9.Write a Python script that fits a polynomial regression model (degree 2) to a dataset and plots the\n",
        "regression curve."
      ],
      "metadata": {
        "id": "6USgN2_SE84B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
        "y = np.sin(X).ravel()\n",
        "y[::5] += 1 * (0.5 - np.random.rand(16))\n",
        "\n",
        "# Create polynomial features (degree 2)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train a linear regression model on the polynomial features\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_poly, y)\n",
        "\n",
        "# Predict values for plotting\n",
        "X_plot = np.linspace(0, 5, 100).reshape(-1, 1)  # Create a range of x values for smooth plot\n",
        "X_plot_poly = poly.fit_transform(X_plot)\n",
        "y_plot_pred = poly_reg.predict(X_plot_poly)\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.plot(X_plot, y_plot_pred, color='red', label='Polynomial Regression')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression (Degree 2)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dgr4w7icztiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 10.Generate synthetic data for simple linear regression (use random values for X and y) and fit a linear\n",
        "regression model to the data. Print the model's coefficient and intercept.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fLgrK3PjE9KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10  # 100 random X values between 0 and 10\n",
        "y = 2 * X + 1 + np.random.randn(100, 1)  # y = 2X + 1 + some noise\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(\"Coefficient:\", model.coef_[0][0])\n",
        "print(\"Intercept:\", model.intercept_[0])"
      ],
      "metadata": {
        "id": "txE2k9HAzzVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Write a Python script that fits polynomial regression models of different degrees to a synthetic dataset and\n",
        "compares their performance."
      ],
      "metadata": {
        "id": "V1EfqAaoE9PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
        "y = np.sin(X).ravel()\n",
        "y[::5] += 1 * (0.5 - np.random.rand(16))\n",
        "\n",
        "# Degrees of polynomials to test\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Results storage\n",
        "results = []\n",
        "\n",
        "# Plot setup\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Iterate through different polynomial degrees\n",
        "for degree in degrees:\n",
        "    # Create polynomial features\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "\n",
        "    # Split data into training and testing sets (optional, but good practice)\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)  # example\n",
        "\n",
        "    # Train the model\n",
        "    poly_reg = LinearRegression()\n",
        "    poly_reg.fit(X_poly, y)\n",
        "\n",
        "    # Evaluate the model (optional - use test data if split)\n",
        "    y_pred = poly_reg.predict(X_poly) # Predicting on training data for simplicity here\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    results.append([degree, mse])\n",
        "\n",
        "    # Plot\n",
        "    X_plot = np.linspace(0, 5, 100).reshape(-1, 1)\n",
        "    X_plot_poly = poly.fit_transform(X_plot)\n",
        "    y_plot_pred = poly_reg.predict(X_plot_poly)\n",
        "    plt.plot(X_plot, y_plot_pred, label=f'Degree {degree}')\n",
        "\n",
        "\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression Models of Different Degrees')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Display results\n",
        "for degree, mse in results:\n",
        "  print(f\"Degree {degree}: MSE = {mse}\")"
      ],
      "metadata": {
        "id": "DK-Kzc6xz4hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.Write a Python script that fits a simple linear regression model with two features and prints the model's\n",
        "coefficients, intercept, and R-squared score."
      ],
      "metadata": {
        "id": "YVT9xMD2E9VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate synthetic data with two features\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 2) * 10  # 100 samples, 2 features\n",
        "y = 2 * X[:, 0] + 3 * X[:, 1] + 1 + np.random.randn(100)  # Target variable with some noise\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print the model's coefficients, intercept, and R-squared score\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"R-squared:\", model.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "or6q3Cj90Ahn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python script that generates synthetic data, fits a linear regression model, and visualizes the\n",
        "regression line along with the data points."
      ],
      "metadata": {
        "id": "FqxGxme8GQcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2 * X + 1 + np.random.randn(100, 1)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict new values\n",
        "X_new = np.array([[0], [10]])\n",
        "y_pred = model.predict(X_new)\n",
        "\n",
        "# Plot the data points and the regression line\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.plot(X_new, y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression on Synthetic Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3PGx6PIR0I5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python script that uses the Variance Inflation Factor (VIF) to check for multicollinearity in a dataset\n",
        "with multiple features."
      ],
      "metadata": {
        "id": "XkJZCRv4GYo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Assuming X is your feature matrix (pandas DataFrame or numpy array)\n",
        "# ... (your code to load or create the dataset and define X) ...\n",
        "# Example using the diamonds dataset from previous questions\n",
        "X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
        "\n",
        "# Display VIF values\n",
        "vif_data"
      ],
      "metadata": {
        "id": "ugDFsJtF0Lca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Assuming X is your feature matrix (pandas DataFrame)\n",
        "# Example: X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "\n",
        "\n",
        "# Print VIF values\n",
        "vif_data"
      ],
      "metadata": {
        "id": "nrLMRnXS0gHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.Write a Python script that generates synthetic data for a polynomial relationship (degree 4), fits a\n",
        "polynomial regression model, and plots the regression curve."
      ],
      "metadata": {
        "id": "6TlvI3plGYle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Generate synthetic data with a polynomial relationship (degree 4)\n",
        "np.random.seed(0)\n",
        "X = np.sort(6 * np.random.rand(80, 1), axis=0)\n",
        "y = 0.5 * X**4 - 2 * X**3 + 3 * X**2 - X + 2 + np.random.randn(80, 1)\n",
        "\n",
        "# Create polynomial features (degree 4)\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train a linear regression model on the polynomial features\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_poly, y)\n",
        "\n",
        "# Predict values for plotting\n",
        "X_plot = np.linspace(0, 6, 100).reshape(-1, 1)  # Create a range of x values for a smooth plot\n",
        "X_plot_poly = poly.fit_transform(X_plot)\n",
        "y_plot_pred = poly_reg.predict(X_plot_poly)\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.plot(X_plot, y_plot_pred, color='red', label='Polynomial Regression (Degree 4)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression on Synthetic Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "3jryNAww09S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 16.Write a Python script that creates a machine learning pipeline with data standardization and a multiple\n",
        "linear regression model, and prints the R-squared score."
      ],
      "metadata": {
        "id": "Ljrqqs81GYhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X and y are your features and target variable respectively\n",
        "# ... (your code to load and prepare the data) ...\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print the R-squared score\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared score: {r_squared}\")"
      ],
      "metadata": {
        "id": "Kxt5A8fs1JjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python script that performs polynomial regression (degree 3) on a synthetic dataset and plots the\n",
        "regression curve."
      ],
      "metadata": {
        "id": "JyHxVJVkGYeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.sort(6 * np.random.rand(80, 1), axis=0)\n",
        "y = np.sin(X).ravel()\n",
        "y[::5] += 1 * (0.5 - np.random.rand(16))\n",
        "\n",
        "# Create polynomial features (degree 3)\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train a linear regression model on the polynomial features\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_poly, y)\n",
        "\n",
        "# Predict values for plotting\n",
        "X_plot = np.linspace(0, 6, 100).reshape(-1, 1)\n",
        "X_plot_poly = poly.fit_transform(X_plot)\n",
        "y_plot_pred = poly_reg.predict(X_plot_poly)\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.plot(X_plot, y_plot_pred, color='red', label='Polynomial Regression (Degree 3)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression on Synthetic Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pm5OwatL1QeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.Write a Python script that performs multiple linear regression on a synthetic dataset with 5 features. Print\n",
        "the R-squared score and model coefficients."
      ],
      "metadata": {
        "id": "0cru2ZKNGYZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y = 2*X[:, 0] - 3*X[:, 1] + 5*X[:, 2] + X[:, 3] - X[:,4] + 1 + np.random.randn(100) # Target variable with some noise\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the R-squared score\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared score: {r_squared}\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(f\"Model coefficients: {model.coef_}\")"
      ],
      "metadata": {
        "id": "REnUuWrT1XiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python script that generates synthetic data for linear regression, fits a model, and visualizes the\n",
        "data points along with the regression line.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mzFiFzyaG7qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2 * X + 1 + np.random.randn(100, 1)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict new values\n",
        "X_new = np.array([[0], [10]])\n",
        "y_pred = model.predict(X_new)\n",
        "\n",
        "# Plot the data points and the regression line\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data Points')\n",
        "plt.plot(X_new, y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression on Synthetic Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dbrXXwCK1byo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Create a synthetic dataset with 3 features and perform multiple linear regression. Print the model's Rsquared score and coefficients."
      ],
      "metadata": {
        "id": "50ok8C57G7m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)  # 100 samples, 3 features\n",
        "y = 2*X[:, 0] - 3*X[:, 1] + 5*X[:, 2] + 1 + np.random.randn(100) # Target variable with some noise\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the R-squared score\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared score: {r_squared}\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(f\"Model coefficients: {model.coef_}\")"
      ],
      "metadata": {
        "id": "FR0twfzt1dzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.Write a Python script that demonstrates how to serialize and deserialize machine learning models using\n",
        "joblib instead of pickling."
      ],
      "metadata": {
        "id": "aWKqZwQZGYHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained linear regression model\n",
        "# ... (your code to train the model) ...\n",
        "\n",
        "# Save the model to a file using joblib\n",
        "filename = 'linear_regression_model.joblib'\n",
        "joblib.dump(model, filename)\n",
        "\n",
        "print(f\"Model saved to {filename}\")\n",
        "\n",
        "# Load the model from the file\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "# Use the loaded model to make predictions\n",
        "# ... (your code to use the loaded model) ..."
      ],
      "metadata": {
        "id": "3DNOb_o91pRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.Write a Python script to perform linear regression with categorical features using one-hot encoding. Use\n",
        "the Seaborn 'tips' dataset."
      ],
      "metadata": {
        "id": "gecsL54iGX5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_cols = ['sex', 'smoker', 'day', 'time']\n",
        "\n",
        "# Perform one-hot encoding\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # sparse=False for easier handling\n",
        "encoded_features = encoder.fit_transform(tips[categorical_cols])\n",
        "feature_names = encoder.get_feature_names_out(categorical_cols)\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=feature_names)\n",
        "\n",
        "# Combine encoded features with numerical features\n",
        "X = pd.concat([tips.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "y = tips['tip']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "epg_54bP1rdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 23.Compare Ridge Regression with Linear Regression on a synthetic dataset and print the coefficients and Rsquared score."
      ],
      "metadata": {
        "id": "-pOXUvITH2su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y = 2*X[:, 0] - 3*X[:, 1] + 5*X[:, 2] + X[:, 3] - X[:,4] + 1 + np.random.randn(100)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_y_pred = lr_model.predict(X_test)\n",
        "lr_r2 = r2_score(y_test, lr_y_pred)\n",
        "\n",
        "print(\"Linear Regression:\")\n",
        "print(\"Coefficients:\", lr_model.coef_)\n",
        "print(\"R-squared:\", lr_r2)\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)  # You can adjust the regularization strength (alpha)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "ridge_y_pred = ridge_model.predict(X_test)\n",
        "ridge_r2 = r2_score(y_test, ridge_y_pred)\n",
        "\n",
        "print(\"\\nRidge Regression:\")\n",
        "print(\"Coefficients:\", ridge_model.coef_)\n",
        "print(\"R-squared:\", ridge_r2)"
      ],
      "metadata": {
        "id": "LWyYj1mM2Am8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python script that uses cross-validation to evaluate a Linear Regression model on a synthetic\n",
        "dataset."
      ],
      "metadata": {
        "id": "RK5lm2KAH25X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y = 2*X[:, 0] - 3*X[:, 1] + 5*X[:, 2] + X[:, 3] - X[:,4] + 1 + np.random.randn(100)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Average R-squared score:\", np.mean(cv_scores))"
      ],
      "metadata": {
        "id": "jgSdGsBI2FLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 25.Write a Python script that compares polynomial regression models of different degrees and prints the Rsquared score for each."
      ],
      "metadata": {
        "id": "ZVOcIWkPICqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic data (replace with your actual data)\n",
        "np.random.seed(0)\n",
        "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
        "y = np.sin(X).ravel()\n",
        "y[::5] += 1 * (0.5 - np.random.rand(16))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Degrees of polynomials to test\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "\n",
        "for degree in degrees:\n",
        "    # Create polynomial features\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_test_poly = poly.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    poly_reg = LinearRegression()\n",
        "    poly_reg.fit(X_train_poly, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = poly_reg.predict(X_test_poly)\n",
        "\n",
        "    # Calculate and print the R-squared score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Degree {degree}: R-squared = {r2}\")"
      ],
      "metadata": {
        "id": "enPEAO3V2MYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}